* bugs
** visit(Dot) has possibly incorrect resultType (DOCUMENT)
** standard function library untested
A bunch of functions, including collection(), doc(), etc are untested.  We
don't know if we're doing the right thing in terms of query generation
based on their args.  See PathOptimizer.fnArgParity
** failure to optimize deep path query properly
see the expression in SearchTest.testTrailingStringCall - it ends up
including some booleans instead of all paths
** don't use schema.xml and solrconfig.xml as test data !
When we change them our tests break!
* missing features
** support for full set of atomic types
The main thing missing is marshalling results from Solr
** namespace support
This might be working, but we need to test
** XQuery!
running XQTS now - down to 1305 failures out of 12008 tests over a few
days we got it down to 147 w/44 ignored.  Now w/external variables implemented:
168 fail (none ignored). 
139
124
Then, running on a larger test
suite: Ran 18623 tests 478 tests failed; 44 ignored (97.5% pass)
*** Now that this is workable, do some global tests:
**** Test performance on XQTS with Saxon alone, and with Lux/Saxon
**** develop an XQTS database query test
Ignore queries that use the emptydocument as input Run the other queries
against the entire test set as context: ie against the sequence of
documents that is collection(xqts) and then run using Lux.  Make sure the
results are consistent; compare timing.
** attribute index support
This might be working, but we need to test
** external XQuery variables
The API can't support it currently, since we only have Saxon, which is
long-lived.  We need to beef up the Context object.
* api design / cleanup
The success of this adventure is going to depend on not only a good
implementation, but also a nice clean understandable code base so others
can extend it too.
** make clean package dependencies 
*** fill out the generic API
*** put all the Saxon-specific code in a package
* better tests generally
**  Object lifecycle
Saxon currently holds the DocIdAllocator, but this should really be in
SaxonContext.  Make sure that long-lived objects stay in Evaluator (Saxon)
and short-lived ones in Context (SaxonContext).
** search test2
refactor and merge w/search test - check opto facts against actual behavior
** search test all index types
include name-index only test
** solr search handler coverage
test all atomic result types
* new indexes
** value indexes
** word indexes
** sorting
* optimization ideas
There are a few more things we can optimize using the "basic" indexing setup
** optimize not(empty(X)) -> exists(X), and not(exists(X)) -> empty(X)
** simplify some path queries
Sometimes we generate a query like 
w(w(w({},\"PLAY\"),\"PERSONAE\" OR \"ACT\"),\"TITLE\")
instead of
w({},\"PLAY\",(\"ACT\" OR \"PERSONAE\"),\"TITLE\")
Is the second one actually better?
** optimize the Optimizer 
It currently generates an entire translated expression tree for every
subtree it attempts to optimize so that we can figure out if that subtree
is ordered or not.  We could possibly cache a translated tree and walk it
in parallel?  Or link subexpressions to it with some kind of map?
** Path indexes random idea
What if instead of collapsing all the paths down so we only store unique
paths, we retained the document structure in some way by listing *all*
paths?  What would that buy?  numerical predicates?
** pre-evaluate some functions, like aggregates:

In cases where we can do this (argument expression is evaluated in the
QueryContext, ie there is no current node, or the argument is the
collection() function), rewrite/wrap/intercept the function to an internal
method (lux:count) that we implement by recursing into a nested query/eval.

Perform static analysis of the argument expression(s) to see if they can be
retrieved minimally by query.  If we can prove that the db query result
count will equal the expression result count, then we can replace the
count() expression with an (indexed, more efficient) query-count()
expression.  exists() and not() can be computed as count()>0 and count()=0,
and we can short-circuit evaluation in the result collector.

This could also hold for max/min when we have an appropriate field.  Maybe
we can even help out w/aggregates like sum/avg?

More complex would be something like: count(//a) + count(//b) ?

*** root()
*** count()
across multiple documents
*** node-uri(), document-uri()
** optimize pagination when we know that #count=#estimate
optimize subsequence when we can - eg the first arg, the sequence, is
entirely indexed.  And even when it's not, make sure we don't iterate on
beyond where we need to - asserting the results are sorted properly.  We're
somewhat limited in our ability to do this right now since we rely on Saxon
to make judgements about sorting, and it doesn't always optimize as
agressively as we would like, at least not in the saxon-HE version.  It
works in some simple cases, though.
* cleanup
** delete dead code
*** get rid of lux:search facts argument
The facts are not serving any purpose now that we are using lazy
evaluation, and we have separate lux:count and lux:exists methods.
** add pagination args to lux:search
This should help work around some of the shortcomings of Saxon's HE
optimizer (re: documentSort) and let us skip document retrieval for docs
prior to the starting doc.
* improve tests
** test namespaces and attributes
queries w/namespaces and attributes have not been tested.
Try indexing and retrieving the reader-test documents
* perf test
some kind of comparison with something
* API packaging
** rename Saxon
** configuration
*** Object Model
Saxon Xdm vs JDOM vs DOM vs ?
*** language
XPath / XQuery
